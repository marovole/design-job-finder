#!/usr/bin/env python3
"""
PM Job Finder - Data Processing & Match Analysis Generator
Processes PM job data, calculates match scores, and generates application support materials.
"""

import csv
import os
from datetime import datetime
from pathlib import Path
from user_profile import (
    get_user_profile,
    get_experience_level_ranges,
    has_ai_agent_relevance,
    get_ai_relevance_bonus_max,
)

try:
    from semantic_matcher import calculate_semantic_skill_match

    SEMANTIC_MATCHER_AVAILABLE = True
except ImportError:
    SEMANTIC_MATCHER_AVAILABLE = False

try:
    from company_analyzer import run_company_analysis, CompanyAnalysisResult

    COMPANY_ANALYZER_AVAILABLE = True
except ImportError:
    COMPANY_ANALYZER_AVAILABLE = False

# Output directory structure for daily runs
OUTPUT_DIR = Path("output")
TODAY = datetime.now().strftime("%Y-%m-%d")
DATE_DIR = OUTPUT_DIR / TODAY


# Create date-based directories
def setup_output_directories():
    """Create output directory structure"""
    try:
        OUTPUT_DIR.mkdir(exist_ok=True)
        DATE_DIR.mkdir(exist_ok=True)
        (DATE_DIR / "match_analysis").mkdir(exist_ok=True)
        (DATE_DIR / "match_analysis" / "high_match").mkdir(parents=True, exist_ok=True)
        (DATE_DIR / "match_analysis" / "good_match").mkdir(parents=True, exist_ok=True)
        (DATE_DIR / "application_materials").mkdir(exist_ok=True)
        (DATE_DIR / "application_materials" / "cover_letters").mkdir(
            parents=True, exist_ok=True
        )
        (DATE_DIR / "company_research").mkdir(exist_ok=True)
    except Exception as e:
        print(f"Warning: Could not create directories: {e}")


def update_latest_symlink():
    """Create or update the 'latest' symlink to point to today's folder"""
    latest_link = OUTPUT_DIR / "latest"
    try:
        if latest_link.is_symlink() or latest_link.exists():
            latest_link.unlink()
        os.symlink(str(DATE_DIR.resolve()), str(latest_link))
    except OSError as e:
        print(f"      Note: Symlink not supported ({e})")


# =============================================================================
# SAMPLE PM JOB DATA - Minimal test data, real data comes from exa_parser
# =============================================================================
# NOTE: This is sample data for testing. In production, use exa_parser.py
# to parse real data from Exa deep researcher.
pm_jobs_data = {
    # Sample AI-focused job for testing AI relevance bonus
    "Sample - AI Jobs": [
        {
            "job_title": "Senior Product Manager - AI Agents",
            "company_name": "Anthropic",
            "job_description": "Shape the future of AI assistants. Work on Claude and define how AI helps humans be more productive. Lead AI agent product strategy.",
            "responsibilities": [
                "Define AI agent features",
                "Work with research team",
                "Shape product vision",
                "Drive user research",
            ],
            "requirements": [
                "5+ years PM experience",
                "AI/ML product experience",
                "LLM understanding",
                "Strong writing skills",
            ],
            "skills_required": [
                "AI/ML",
                "LLM",
                "AI Agent",
                "Product Strategy",
                "User Research",
            ],
            "job_level": "Senior",
            "job_type": "Full-time",
            "remote_policy": "Full Remote",
            "salary_range": "$200,000 - $300,000/year",
            "salary_min_usd": 200000,
            "salary_max_usd": 300000,
            "equity_offered": True,
            "company_stage": "Series D+",
            "funding_round": "Series D",
            "funding_amount": "$4B",
            "company_size": "500-1000",
            "company_industry": "AI/ML",
            "product_type": "ToB SaaS",
            "location": "Remote (Global)",
            "timezone_requirements": "Flexible",
            "visa_sponsorship": True,
            "application_url": "https://anthropic.com/careers",
            "posted_date": "2026-01-07",
            "recruiter_email": "jobs@anthropic.com",
            "recruiter_linkedin": None,
        },
    ],
    # Sample Developer Tools job
    "Sample - Dev Tools": [
        {
            "job_title": "Founding Product Manager",
            "company_name": "Resend",
            "job_description": "Join as the first PM at a fast-growing developer email infrastructure company. Shape product strategy from the ground up.",
            "responsibilities": [
                "Define product vision",
                "Work directly with founders",
                "Ship features weekly",
                "Talk to customers daily",
            ],
            "requirements": [
                "5+ years PM experience",
                "Developer tools or API experience",
                "Startup experience",
                "Technical background preferred",
            ],
            "skills_required": [
                "Developer Tools",
                "API Products",
                "Startup",
                "Technical PM",
            ],
            "job_level": "Senior",
            "job_type": "Full-time",
            "remote_policy": "Full Remote",
            "salary_range": "$150,000 - $200,000/year + 0.5-1% equity",
            "salary_min_usd": 150000,
            "salary_max_usd": 200000,
            "equity_offered": True,
            "company_stage": "Series A",
            "funding_round": "Series A",
            "funding_amount": "$18M",
            "company_size": "20-50",
            "company_industry": "Developer Tools",
            "product_type": "ToB SaaS",
            "location": "Remote (Global)",
            "timezone_requirements": "Americas preferred",
            "visa_sponsorship": False,
            "application_url": "https://resend.com/careers",
            "posted_date": "2026-01-08",
            "recruiter_email": "careers@resend.com",
            "recruiter_linkedin": None,
        },
    ],
    # Sample non-AI job for comparison
    "Sample - E-commerce": [
        {
            "job_title": "Senior PM - Marketplace",
            "company_name": "Faire",
            "job_description": "Build the future of wholesale commerce. Own the retailer experience and drive GMV growth.",
            "responsibilities": [
                "Own retailer experience",
                "Drive marketplace growth",
                "Define feature roadmap",
                "Work with data team",
            ],
            "requirements": [
                "5+ years PM experience",
                "Marketplace experience",
                "E-commerce background",
                "Data-driven",
            ],
            "skills_required": ["Marketplace", "E-commerce", "Growth", "Data Analysis"],
            "job_level": "Senior",
            "job_type": "Full-time",
            "remote_policy": "Full Remote",
            "salary_range": "$160,000 - $220,000/year",
            "salary_min_usd": 160000,
            "salary_max_usd": 220000,
            "equity_offered": True,
            "company_stage": "Series G",
            "funding_round": "Series G",
            "funding_amount": "$400M",
            "company_size": "1000-2000",
            "company_industry": "E-commerce/Marketplace",
            "product_type": "ToB SaaS",
            "location": "Remote (US/Canada)",
            "timezone_requirements": "North America",
            "visa_sponsorship": False,
            "application_url": "https://faire.com/careers",
            "posted_date": "2026-01-04",
            "recruiter_email": "talent@faire.com",
            "recruiter_linkedin": None,
        },
    ],
}


# =============================================================================
# MATCH SCORING ALGORITHM
# =============================================================================


def calculate_match_score(job, user_profile):
    """
    Calculate job match score 0-100 based on user profile.

    Weight Distribution:
    - Experience Level Match: 25 points
    - Industry/Product Type Match: 20 points
    - Remote Policy Match: 20 points
    - Company Stage Match: 15 points
    - Salary Competitiveness: 10 points
    - Skills Match: 10 points

    Returns: (score, breakdown_dict, highlights, concerns)
    """
    score = 0
    breakdown = {}
    highlights = []
    concerns = []

    # === 1. Experience Level Match (25 points) ===
    job_level = job.get("job_level", "Mid")
    user_years = user_profile.get("years_experience", 8)
    level_ranges = get_experience_level_ranges()

    min_years, max_years = level_ranges.get(job_level, (5, 10))

    if min_years <= user_years <= max_years:
        breakdown["experience_match"] = 25
        highlights.append(f"{user_years}å¹´ç»éªŒå®Œç¾ŽåŒ¹é…{job_level}çº§åˆ«")
    elif user_years > max_years:
        breakdown["experience_match"] = 18
        concerns.append(f"å¯èƒ½èµ„åŽ†è¿‡é«˜ ({user_years}å¹´ vs {job_level}çº§åˆ«)")
    elif user_years >= min_years - 2:
        breakdown["experience_match"] = 15
        highlights.append("ç»éªŒåŸºæœ¬åŒ¹é…")
    else:
        breakdown["experience_match"] = 5
        concerns.append("ç»éªŒå¹´é™ä¸è¶³")

    score += breakdown["experience_match"]

    # === 2. Industry/Product Type Match (20 points) ===
    job_industry = job.get("company_industry", "").lower()
    product_type = job.get("product_type", "").lower()

    industry_score = 0
    for pref_industry, weight in user_profile.get("preferred_industries", {}).items():
        if (
            pref_industry.lower() in job_industry
            or pref_industry.lower() in product_type
        ):
            industry_score = max(industry_score, int(20 * weight))
            if weight >= 0.9:
                highlights.append(f"è¡Œä¸šåŒ¹é…: {pref_industry}")
            break

    if industry_score == 0:
        industry_score = 6
        concerns.append(f"éžé¦–é€‰è¡Œä¸š: {job.get('company_industry', 'Unknown')}")

    breakdown["industry_match"] = industry_score
    score += industry_score

    # === 3. Remote Policy Match (20 points) ===
    remote_policy = job.get("remote_policy", "On-site")
    location_prefs = user_profile.get("location_preferences", {})

    remote_score = 0
    for policy, weight in location_prefs.items():
        if policy.lower() in remote_policy.lower():
            remote_score = int(20 * weight)
            if weight >= 0.8:
                highlights.append(f"è¿œç¨‹æ”¿ç­–åŒ¹é…: {remote_policy}")
            break

    if remote_score == 0:
        remote_score = 4
        concerns.append(f"è¿œç¨‹æ”¿ç­–: {remote_policy}")

    breakdown["remote_match"] = remote_score
    score += remote_score

    # === 4. Company Stage Match (15 points) ===
    company_stage = job.get("company_stage", "Unknown")
    stage_prefs = user_profile.get("preferred_company_stages", {})

    stage_score = 0
    for stage, weight in stage_prefs.items():
        if stage.lower() in company_stage.lower():
            stage_score = int(15 * weight)
            if weight >= 0.9:
                highlights.append(f"å…¬å¸é˜¶æ®µåŒ¹é…: {company_stage}")
            break

    if stage_score == 0:
        stage_score = 5

    breakdown["company_stage_match"] = stage_score
    score += stage_score

    # === 5. Salary Competitiveness (10 points) ===
    salary_mid = (job.get("salary_min_usd", 0) + job.get("salary_max_usd", 0)) / 2
    salary_target = user_profile.get("salary_expectation_target", 200000)
    salary_min = user_profile.get("salary_expectation_min", 150000)

    if salary_mid >= salary_target:
        breakdown["salary_match"] = 10
        highlights.append(f"è–ªèµ„è¶…è¿‡æœŸæœ›: ${salary_mid:,.0f}")
    elif salary_mid >= salary_min:
        breakdown["salary_match"] = 7
        highlights.append(f"è–ªèµ„è¾¾åˆ°æœ€ä½Žè¦æ±‚: ${salary_mid:,.0f}")
    elif salary_mid >= salary_min * 0.8:
        breakdown["salary_match"] = 4
        concerns.append(f"è–ªèµ„ç•¥ä½ŽäºŽæœŸæœ›: ${salary_mid:,.0f}")
    else:
        breakdown["salary_match"] = 2
        concerns.append(f"è–ªèµ„è¾ƒä½Ž: ${salary_mid:,.0f}")

    score += breakdown["salary_match"]

    # === 6. Skills Match (10 points base, uses semantic matching if available) ===
    required_skills = job.get("skills_required", [])
    requirements = job.get("requirements", [])

    if SEMANTIC_MATCHER_AVAILABLE and required_skills:
        # Use semantic matching with LLM
        try:
            skill_score, matched_skills, skill_gaps = calculate_semantic_skill_match(
                requirements, required_skills, user_profile, use_llm=True
            )
            breakdown["skills_match"] = int(10 * skill_score)
            if skill_score >= 0.7:
                highlights.append(f"æŠ€èƒ½è¯­ä¹‰åŒ¹é…åº¦é«˜: {len(matched_skills)}é¡¹åŒ¹é…")
            job["_semantic_matched_skills"] = matched_skills
            job["_semantic_skill_gaps"] = skill_gaps
        except Exception:
            # Fallback to keyword matching
            breakdown["skills_match"] = _keyword_skill_match(
                required_skills, user_profile
            )
    elif required_skills:
        # Keyword matching fallback
        breakdown["skills_match"] = _keyword_skill_match(required_skills, user_profile)
        required_skills_lower = set(s.lower() for s in required_skills)
        user_skills = set(
            s.lower()
            for s in user_profile.get("core_skills", [])
            + user_profile.get("technical_skills", [])
        )
        overlap = len(required_skills_lower & user_skills)
        if overlap / len(required_skills_lower) >= 0.7:
            highlights.append(f"æŠ€èƒ½åŒ¹é…åº¦é«˜: {overlap}/{len(required_skills_lower)}")
    else:
        breakdown["skills_match"] = 5

    score += breakdown["skills_match"]

    # === 7. AI Agent Relevance Bonus (up to 15 extra points) ===
    is_ai_relevant, ai_relevance = has_ai_agent_relevance(job)
    ai_bonus_max = get_ai_relevance_bonus_max()

    if is_ai_relevant:
        ai_bonus = int(ai_bonus_max * ai_relevance)
        breakdown["ai_relevance_bonus"] = ai_bonus
        score += ai_bonus
        if ai_relevance >= 0.6:
            highlights.append(
                f"ðŸ¤– AI Agent ç›¸å…³èŒä½ (åŒ¹é…åº¦ {ai_relevance * 100:.0f}%)"
            )
        elif ai_relevance >= 0.3:
            highlights.append(f"AI ç›¸å…³èŒä½")
    else:
        breakdown["ai_relevance_bonus"] = 0

    # Max score is now 115 (100 base + 15 AI bonus), normalize for A+ tier
    return score, breakdown, highlights, concerns


def _keyword_skill_match(required_skills: list, user_profile: dict) -> int:
    """Fallback keyword-based skill matching."""
    required_skills_lower = set(s.lower() for s in required_skills)
    user_skills = set(
        s.lower()
        for s in user_profile.get("core_skills", [])
        + user_profile.get("technical_skills", [])
        + user_profile.get("ai_agent_skills", [])
    )

    if not required_skills_lower:
        return 5

    overlap = len(required_skills_lower & user_skills)
    skill_ratio = overlap / len(required_skills_lower)
    return int(10 * skill_ratio)


def determine_match_label(score):
    """Convert score to match label. Supports A+ tier for AI-relevant jobs (score > 100)."""
    if score >= 100:
        return "A+çº§-æžé«˜åŒ¹é…(AI)"
    elif score >= 80:
        return "Açº§-æžé«˜åŒ¹é…"
    elif score >= 60:
        return "Bçº§-é«˜åŒ¹é…"
    elif score >= 40:
        return "Cçº§-ä¸­åŒ¹é…"
    else:
        return "Dçº§-ä½ŽåŒ¹é…"


# =============================================================================
# APPLICATION SUPPORT GENERATION
# =============================================================================


def generate_resume_suggestions(job):
    """Generate resume focus suggestions for a specific job"""
    suggestions = []

    # Based on job level
    level = job.get("job_level", "Senior")
    if level in ["Lead", "Director", "VP"]:
        suggestions.append("çªå‡ºå›¢é˜Ÿç®¡ç†å’Œé¢†å¯¼åŠ›ç»éªŒ")
        suggestions.append("å¼ºè°ƒæˆ˜ç•¥è§„åˆ’å’Œå•†ä¸šå½±å“")
    else:
        suggestions.append("å±•ç¤ºç‹¬ç«‹è´Ÿè´£äº§å“çº¿çš„ç»éªŒ")
        suggestions.append("é‡åŒ–äº§å“æŒ‡æ ‡æˆæžœ (ç”¨æˆ·å¢žé•¿ã€æ”¶å…¥ã€ç•™å­˜ç­‰)")

    # Based on industry
    industry = job.get("company_industry", "")
    if "AI" in industry or "ML" in industry:
        suggestions.append("çªå‡ºAI/MLäº§å“ç»éªŒå’ŒæŠ€æœ¯ç†è§£")
    if "SaaS" in industry or "ToB" in job.get("product_type", ""):
        suggestions.append("å¼ºè°ƒB2Bäº§å“ç»éªŒå’Œä¼ä¸šå®¢æˆ·ç®¡ç†")
    if "Developer" in industry:
        suggestions.append("å±•ç¤ºæŠ€æœ¯èƒŒæ™¯å’Œå¼€å‘è€…ç”Ÿæ€ç†è§£")

    # Based on company stage
    stage = job.get("company_stage", "")
    if stage in ["Seed", "Series A", "Series B"]:
        suggestions.append("çªå‡ºä»Ž0åˆ°1çš„äº§å“ç»éªŒ")
        suggestions.append("å¼ºè°ƒå¿«é€Ÿè¿­ä»£å’Œåˆ›ä¸šå¿ƒæ€")
    elif stage in ["Public", "Enterprise"]:
        suggestions.append("å¼ºè°ƒå¤§è§„æ¨¡äº§å“è¿è¥ç»éªŒ")
        suggestions.append("å±•ç¤ºè·¨éƒ¨é—¨åä½œèƒ½åŠ›")

    return suggestions


def generate_cover_letter_points(job):
    """Generate cover letter talking points for a specific job"""
    points = []

    company = job.get("company_name", "")
    title = job.get("job_title", "")

    points.append(f"å¼€ç¯‡: è¡¨è¾¾å¯¹{company}äº§å“çš„çœŸå®žçƒ­æƒ…å’Œäº†è§£")

    # Based on product type
    product_type = job.get("product_type", "")
    if "ToB" in product_type:
        points.append("ä¸­æ®µ: åˆ†äº«B2Bäº§å“ç»éªŒï¼Œç‰¹åˆ«æ˜¯ä¼ä¸šå®¢æˆ·éœ€æ±‚ç†è§£")
    elif "ToC" in product_type:
        points.append("ä¸­æ®µ: å±•ç¤ºæ¶ˆè´¹è€…äº§å“ç›´è§‰å’Œç”¨æˆ·å¢žé•¿ç»éªŒ")

    # Based on company stage
    stage = job.get("company_stage", "")
    if stage in ["Seed", "Series A", "Series B"]:
        points.append("å¼ºè°ƒ: åˆ›ä¸šçŽ¯å¢ƒé€‚åº”èƒ½åŠ›ï¼Œå¿«é€Ÿå­¦ä¹ å’Œæ‰§è¡Œ")
    else:
        points.append("å¼ºè°ƒ: åœ¨å¤æ‚ç»„ç»‡ä¸­æŽ¨åŠ¨å˜é©çš„èƒ½åŠ›")

    points.append(f"ç»“å°¾: æ˜Žç¡®è¡¨è¾¾å¯¹{title}èŒä½çš„å…´è¶£å’Œè´¡çŒ®æ„¿æ™¯")

    return points


def generate_interview_prep(job):
    """Generate interview preparation notes"""
    prep_notes = []

    company = job.get("company_name", "")
    industry = job.get("company_industry", "")

    prep_notes.append(f"ç ”ç©¶{company}çš„äº§å“çº¿å’Œæœ€æ–°åŠ¨æ€")
    prep_notes.append(f"å‡†å¤‡{industry}è¡Œä¸šè¶‹åŠ¿çš„è§è§£")
    prep_notes.append("å‡†å¤‡2-3ä¸ªä½ ä¸»å¯¼çš„äº§å“æ¡ˆä¾‹ï¼ŒåŒ…å«å…·ä½“æ•°æ®")
    prep_notes.append("æ€è€ƒå¯¹è¯¥èŒä½çš„å‰90å¤©è®¡åˆ’")

    # Based on job level
    level = job.get("job_level", "")
    if level in ["Lead", "Director", "VP"]:
        prep_notes.append("å‡†å¤‡å›¢é˜Ÿç®¡ç†å’Œäººæ‰å‘å±•çš„ç»éªŒåˆ†äº«")
        prep_notes.append("å‡†å¤‡äº§å“æˆ˜ç•¥å’Œæ„¿æ™¯ç±»é—®é¢˜")

    # Based on skills
    skills = job.get("skills_required", [])
    if "AI" in str(skills) or "ML" in str(skills):
        prep_notes.append("å‡†å¤‡AIäº§å“ä¼¦ç†å’Œè´Ÿè´£ä»»AIçš„è§‚ç‚¹")

    return prep_notes


# =============================================================================
# DATA PROCESSING
# =============================================================================


def normalize_company_name(name: str) -> str:
    """Normalize company name for deduplication."""
    name = name.lower().strip()
    # Remove common suffixes
    for suffix in [
        " inc",
        " inc.",
        " llc",
        " ltd",
        " limited",
        " corp",
        " corporation",
        " ug",
        " gmbh",
    ]:
        if name.endswith(suffix):
            name = name[: -len(suffix)]
    return name.strip()


def normalize_job_key(job: dict) -> str:
    """Generate unique key for job deduplication."""
    company = normalize_company_name(job.get("company_name", ""))
    title = job.get("job_title", "").lower()

    # Remove level words to match similar positions
    for level in [
        "senior ",
        "lead ",
        "principal ",
        "staff ",
        "head of ",
        "director of ",
        "vp of ",
    ]:
        title = title.replace(level, "")

    # Extract first 3 meaningful words
    words = [w for w in title.split() if len(w) > 2][:3]
    title_key = "_".join(words)

    return f"{company}_{title_key}"


def calculate_job_completeness(job: dict) -> int:
    """Calculate information completeness score for a job."""
    score = 0
    if job.get("salary_min_usd"):
        score += 3
    if job.get("recruiter_email"):
        score += 3
    if job.get("recruiter_linkedin"):
        score += 2
    if len(job.get("skills_required", [])) > 3:
        score += 2
    if len(job.get("job_description", "")) > 200:
        score += 1
    if job.get("equity_offered"):
        score += 1
    if job.get("funding_amount"):
        score += 1
    return score


def deduplicate_jobs(jobs: list) -> list:
    """
    Deduplicate jobs across platforms, keeping the most complete version.

    Args:
        jobs: List of job dictionaries

    Returns:
        Deduplicated list of jobs
    """
    seen = {}

    for job in jobs:
        key = normalize_job_key(job)

        if key not in seen:
            seen[key] = job
        else:
            # Keep the more complete version
            existing_score = calculate_job_completeness(seen[key])
            new_score = calculate_job_completeness(job)

            if new_score > existing_score:
                # Keep new job but merge source platforms
                old_platform = seen[key].get("source_platform", "")
                new_platform = job.get("source_platform", "")
                if old_platform and old_platform != new_platform:
                    job["source_platforms"] = f"{new_platform}, {old_platform}"
                seen[key] = job

    return list(seen.values())


def process_jobs(jobs_data: dict = None):
    """
    Process all job data and generate match analysis.

    Args:
        jobs_data: Dictionary of {platform: [jobs]} or None to use sample data

    Returns:
        List of processed jobs sorted by match score
    """
    user_profile = get_user_profile()
    all_jobs = []

    # Use provided data or fallback to sample data
    data_source = jobs_data if jobs_data is not None else pm_jobs_data

    # Flatten all jobs from all platforms
    for platform, jobs in data_source.items():
        for job in jobs:
            job["source_platform"] = platform
            job["data_collection_date"] = TODAY

            # Calculate match score
            score, breakdown, highlights, concerns = calculate_match_score(
                job, user_profile
            )
            job["match_score"] = score
            job["match_label"] = determine_match_label(score)
            job["match_breakdown"] = breakdown
            job["match_highlights"] = highlights
            job["match_concerns"] = concerns

            # Generate application support
            job["resume_suggestions"] = generate_resume_suggestions(job)
            job["cover_letter_points"] = generate_cover_letter_points(job)
            job["interview_prep"] = generate_interview_prep(job)

            # Calculate days since posted
            try:
                posted = datetime.strptime(job.get("posted_date", TODAY), "%Y-%m-%d")
                job["days_since_posted"] = (datetime.now() - posted).days
            except Exception:
                job["days_since_posted"] = 0

            all_jobs.append(job)

    # Deduplicate jobs across platforms
    original_count = len(all_jobs)
    all_jobs = deduplicate_jobs(all_jobs)
    dedup_count = original_count - len(all_jobs)
    if dedup_count > 0:
        print(
            f"      Deduplicated: {original_count} -> {len(all_jobs)} ({dedup_count} duplicates removed)"
        )

    # Sort by match score (descending)
    all_jobs.sort(key=lambda x: x["match_score"], reverse=True)

    return all_jobs


# =============================================================================
# OUTPUT GENERATION
# =============================================================================


def save_to_csv(jobs):
    """Save jobs to CSV file"""
    filename = DATE_DIR / f"pm_jobs_{TODAY}.csv"

    fieldnames = [
        "åŒ¹é…ç­‰çº§",
        "åŒ¹é…åˆ†æ•°",
        "æ•°æ®æ¥æº",
        "èŒä½åç§°",
        "å…¬å¸åç§°",
        "èŒä½çº§åˆ«",
        "å·¥ä½œç±»åž‹",
        "è¿œç¨‹æ”¿ç­–",
        "è–ªèµ„èŒƒå›´",
        "è–ªèµ„ä¸‹é™USD",
        "è–ªèµ„ä¸Šé™USD",
        "å…¬å¸é˜¶æ®µ",
        "èžèµ„è½®æ¬¡",
        "èžèµ„é‡‘é¢",
        "å…¬å¸è§„æ¨¡",
        "è¡Œä¸š",
        "äº§å“ç±»åž‹",
        "å·¥ä½œåœ°ç‚¹",
        "æ—¶åŒºè¦æ±‚",
        "ç­¾è¯æ”¯æŒ",
        "ç”³è¯·é“¾æŽ¥",
        "å‘å¸ƒæ—¥æœŸ",
        "å‘å¸ƒå¤©æ•°",
        "æ‹›è˜è€…é‚®ç®±",
        "æ‹›è˜è€…LinkedIn",
        "åŒ¹é…äº®ç‚¹",
        "åŒ¹é…é¡¾è™‘",
        "ç®€åŽ†é‡ç‚¹å»ºè®®",
        "é¢è¯•å‡†å¤‡è¦ç‚¹",
    ]

    with open(filename, "w", newline="", encoding="utf-8-sig") as f:
        writer = csv.DictWriter(f, fieldnames=fieldnames)
        writer.writeheader()

        for job in jobs:
            row = {
                "åŒ¹é…ç­‰çº§": job.get("match_label", ""),
                "åŒ¹é…åˆ†æ•°": job.get("match_score", 0),
                "æ•°æ®æ¥æº": job.get("source_platform", ""),
                "èŒä½åç§°": job.get("job_title", ""),
                "å…¬å¸åç§°": job.get("company_name", ""),
                "èŒä½çº§åˆ«": job.get("job_level", ""),
                "å·¥ä½œç±»åž‹": job.get("job_type", ""),
                "è¿œç¨‹æ”¿ç­–": job.get("remote_policy", ""),
                "è–ªèµ„èŒƒå›´": job.get("salary_range", ""),
                "è–ªèµ„ä¸‹é™USD": job.get("salary_min_usd", ""),
                "è–ªèµ„ä¸Šé™USD": job.get("salary_max_usd", ""),
                "å…¬å¸é˜¶æ®µ": job.get("company_stage", ""),
                "èžèµ„è½®æ¬¡": job.get("funding_round", ""),
                "èžèµ„é‡‘é¢": job.get("funding_amount", ""),
                "å…¬å¸è§„æ¨¡": job.get("company_size", ""),
                "è¡Œä¸š": job.get("company_industry", ""),
                "äº§å“ç±»åž‹": job.get("product_type", ""),
                "å·¥ä½œåœ°ç‚¹": job.get("location", ""),
                "æ—¶åŒºè¦æ±‚": job.get("timezone_requirements", ""),
                "ç­¾è¯æ”¯æŒ": "æ˜¯" if job.get("visa_sponsorship") else "å¦",
                "ç”³è¯·é“¾æŽ¥": job.get("application_url", ""),
                "å‘å¸ƒæ—¥æœŸ": job.get("posted_date", ""),
                "å‘å¸ƒå¤©æ•°": job.get("days_since_posted", ""),
                "æ‹›è˜è€…é‚®ç®±": job.get("recruiter_email", ""),
                "æ‹›è˜è€…LinkedIn": job.get("recruiter_linkedin", ""),
                "åŒ¹é…äº®ç‚¹": " | ".join(job.get("match_highlights", [])),
                "åŒ¹é…é¡¾è™‘": " | ".join(job.get("match_concerns", [])),
                "ç®€åŽ†é‡ç‚¹å»ºè®®": " | ".join(job.get("resume_suggestions", [])),
                "é¢è¯•å‡†å¤‡è¦ç‚¹": " | ".join(job.get("interview_prep", [])),
            }
            writer.writerow(row)

    print(f"      CSV saved: {filename}")
    return filename


def generate_summary_report(jobs):
    """Generate summary markdown report"""
    filename = DATE_DIR / f"pm_jobs_summary_{TODAY}.md"

    user_profile = get_user_profile()

    # Calculate statistics
    total = len(jobs)
    a_level = sum(1 for j in jobs if j["match_score"] >= 80)
    b_level = sum(1 for j in jobs if 60 <= j["match_score"] < 80)
    c_level = sum(1 for j in jobs if 40 <= j["match_score"] < 60)
    d_level = sum(1 for j in jobs if j["match_score"] < 40)
    avg_score = sum(j["match_score"] for j in jobs) / total if total > 0 else 0
    remote_jobs = sum(1 for j in jobs if "remote" in j.get("remote_policy", "").lower())
    startup_jobs = sum(
        1
        for j in jobs
        if j.get("company_stage", "") in ["Seed", "Series A", "Series B"]
    )

    # Group by platform
    by_platform = {}
    for job in jobs:
        platform = job.get("source_platform", "Unknown")
        if platform not in by_platform:
            by_platform[platform] = []
        by_platform[platform].append(job)

    report = f"""# PM Job Match Analysis Report

**Generated:** {datetime.now().strftime("%Y-%m-%d %H:%M")}
**User Profile:** {user_profile["years_experience"]}+ years PM | {", ".join(user_profile["target_level"])} level | Remote preferred

---

## Executive Summary

| Metric | Value |
|--------|-------|
| Total Jobs Found | {total} |
| Açº§ Matches (â‰¥80) | {a_level} ({a_level / total * 100:.1f}%) |
| Bçº§ Matches (â‰¥60) | {b_level} ({b_level / total * 100:.1f}%) |
| Cçº§ Matches (â‰¥40) | {c_level} ({c_level / total * 100:.1f}%) |
| Dçº§ Matches (<40) | {d_level} ({d_level / total * 100:.1f}%) |
| Average Match Score | {avg_score:.1f} |
| Jobs with Full Remote | {remote_jobs} ({remote_jobs / total * 100:.1f}%) |
| Early-Stage Startups | {startup_jobs} ({startup_jobs / total * 100:.1f}%) |

---

## Top 10 Best Matches

"""

    # Top 10 jobs
    for i, job in enumerate(jobs[:10], 1):
        report += f"""### {i}. {job["job_title"]} (Score: {job["match_score"]}/100)
- **Company:** {job["company_name"]} ({job.get("company_stage", "N/A")}, {job.get("funding_round", "N/A")})
- **Salary:** {job.get("salary_range", "N/A")} {"+ equity" if job.get("equity_offered") else ""}
- **Remote:** {job.get("remote_policy", "N/A")}
- **Industry:** {job.get("company_industry", "N/A")} ({job.get("product_type", "N/A")})
- **Match Highlights:**
{chr(10).join("  - " + h for h in job.get("match_highlights", []))}
- **Quick Apply:** [{job.get("application_url", "N/A")}]({job.get("application_url", "#")})
- **Resume Focus:** {job.get("resume_suggestions", ["N/A"])[0] if job.get("resume_suggestions") else "N/A"}

"""

    # By Platform
    report += """---

## By Platform

| Platform | Jobs | Avg Match Score |
|----------|------|-----------------|
"""
    for platform, platform_jobs in sorted(
        by_platform.items(), key=lambda x: -len(x[1])
    ):
        avg = sum(j["match_score"] for j in platform_jobs) / len(platform_jobs)
        report += f"| {platform} | {len(platform_jobs)} | {avg:.0f} |\n"

    # Weekly Action Plan
    report += f"""
---

## Weekly Action Plan

### This Week ({TODAY})
1. **Apply to top {min(5, a_level)} Açº§ matches** (highest priority)
2. **Customize resume** for {jobs[0]["company_industry"] if jobs else "target industry"} focus
3. **Research company cultures** for top matches

### Next Week
1. **Apply to remaining Açº§ matches**
2. **Begin Bçº§ applications** (customize cover letters)
3. **Follow up on submitted applications**

---

*Generated by PM Job Finder Skill*
"""

    with open(filename, "w", encoding="utf-8") as f:
        f.write(report)

    print(f"      Summary saved: {filename}")
    return filename


def generate_match_analysis_files(jobs):
    """Generate individual match analysis files for high-match jobs"""
    high_match_dir = DATE_DIR / "match_analysis" / "high_match"
    good_match_dir = DATE_DIR / "match_analysis" / "good_match"

    count = 0
    for job in jobs:
        if job["match_score"] < 60:
            continue

        # Determine directory
        if job["match_score"] >= 80:
            target_dir = high_match_dir
        else:
            target_dir = good_match_dir

        # Create filename
        safe_company = job["company_name"].replace(" ", "_").replace("/", "_")[:20]
        safe_title = job["job_title"].replace(" ", "_").replace("/", "_")[:30]
        filename = target_dir / f"job_{count + 1:03d}_{safe_company}_{safe_title}.md"

        content = f"""# Match Analysis: {job["job_title"]}

## Job Information
- **Company:** {job["company_name"]}
- **Position:** {job["job_title"]}
- **Level:** {job.get("job_level", "N/A")}
- **Type:** {job.get("job_type", "N/A")}
- **Remote:** {job.get("remote_policy", "N/A")}
- **Location:** {job.get("location", "N/A")}
- **Salary:** {job.get("salary_range", "N/A")}

## Company Information
- **Stage:** {job.get("company_stage", "N/A")}
- **Funding:** {job.get("funding_round", "N/A")} ({job.get("funding_amount", "N/A")})
- **Size:** {job.get("company_size", "N/A")}
- **Industry:** {job.get("company_industry", "N/A")}
- **Product Type:** {job.get("product_type", "N/A")}

---

## Match Analysis

**Overall Score:** {job["match_score"]}/100 ({job["match_label"]})

### Score Breakdown
| Dimension | Score |
|-----------|-------|
| Experience Match | {job["match_breakdown"].get("experience_match", 0)}/25 |
| Industry Match | {job["match_breakdown"].get("industry_match", 0)}/20 |
| Remote Match | {job["match_breakdown"].get("remote_match", 0)}/20 |
| Company Stage | {job["match_breakdown"].get("company_stage_match", 0)}/15 |
| Salary Match | {job["match_breakdown"].get("salary_match", 0)}/10 |
| Skills Match | {job["match_breakdown"].get("skills_match", 0)}/10 |

### Match Highlights
{chr(10).join("- " + h for h in job.get("match_highlights", ["No highlights"]))}

### Potential Concerns
{chr(10).join("- " + c for c in job.get("match_concerns", ["No concerns"]))}

---

## Application Support

### Resume Focus
{chr(10).join("- " + s for s in job.get("resume_suggestions", []))}

### Cover Letter Talking Points
{chr(10).join("- " + p for p in job.get("cover_letter_points", []))}

### Interview Preparation
{chr(10).join("- " + n for n in job.get("interview_prep", []))}

---

## Quick Links
- **Apply:** {job.get("application_url", "N/A")}
- **Recruiter Email:** {job.get("recruiter_email", "N/A")}
- **Recruiter LinkedIn:** {job.get("recruiter_linkedin", "N/A")}
- **Posted:** {job.get("posted_date", "N/A")} ({job.get("days_since_posted", 0)} days ago)

---

*Generated by PM Job Finder Skill on {TODAY}*
"""

        with open(filename, "w", encoding="utf-8") as f:
            f.write(content)

        count += 1

    print(f"      Match analysis files generated: {count}")
    return count


def save_readme():
    """Save README file with usage instructions"""
    filename = DATE_DIR / "README.md"

    content = f"""# PM Job Finder Output - {TODAY}

## Files in this folder

| File | Description |
|------|-------------|
| `pm_jobs_{TODAY}.csv` | Complete job listings with match scores |
| `pm_jobs_summary_{TODAY}.md` | Match analysis summary report |
| `match_analysis/` | Individual job match analysis files |
| `application_materials/` | Application support materials |
| `company_research/` | Company research reports |
| `company_research/company_requirements_analysis_{TODAY}.md` | **NEW** Company requirements deep analysis with 5 key research directions |

## How to use

1. **Review Summary Report** - Start with `pm_jobs_summary_{TODAY}.md` for an overview
2. **Company Deep Analysis** - Check `company_research/company_requirements_analysis_{TODAY}.md` for talent insights and research directions
3. **Filter CSV** - Use Excel/Sheets to filter by match score (Açº§ â‰¥80, Bçº§ â‰¥60)
4. **Read Match Analysis** - Check `match_analysis/high_match/` for detailed analysis of top matches
5. **Apply Strategically** - Use resume suggestions and cover letter points from match analysis files

## Match Score Breakdown

- **Açº§ (â‰¥80)**: Excellent match - apply immediately
- **Bçº§ (60-79)**: Good match - strong candidate
- **Cçº§ (40-59)**: Moderate match - consider if interested
- **Dçº§ (<40)**: Low match - likely not ideal fit

## Generated by

PM Job Finder Skill v1.0
"""

    with open(filename, "w", encoding="utf-8") as f:
        f.write(content)

    return filename


# =============================================================================
# MAIN EXECUTION
# =============================================================================


def main():
    """Main execution function"""
    print(f"\n{'=' * 60}")
    print("PM Job Finder - Data Processing & Match Analysis")
    print(f"{'=' * 60}\n")

    print("[0/6] Setting up output structure...")
    setup_output_directories()
    update_latest_symlink()
    print(f"      Output directory: {DATE_DIR}")

    print("\n[1/6] Processing jobs and calculating match scores...")
    jobs = process_jobs()
    print(f"      Total jobs processed: {len(jobs)}")
    print(f"      Açº§ matches: {sum(1 for j in jobs if j['match_score'] >= 80)}")
    print(f"      Bçº§ matches: {sum(1 for j in jobs if 60 <= j['match_score'] < 80)}")

    print("\n[2/6] Saving to CSV...")
    save_to_csv(jobs)

    print("\n[3/6] Generating summary report...")
    generate_summary_report(jobs)

    print("\n[4/6] Generating match analysis files...")
    generate_match_analysis_files(jobs)

    print("\n[5/6] Running company requirements deep analysis...")
    company_analysis_result = None
    if COMPANY_ANALYZER_AVAILABLE:
        try:
            company_analysis_result, report_path = run_company_analysis(
                jobs=jobs, output_dir=DATE_DIR, use_llm=False
            )
            print(
                f"      Companies analyzed: {company_analysis_result.total_companies}"
            )
            print(f"      Report saved: {report_path}")
        except Exception as e:
            print(f"      Warning: Company analysis failed: {e}")
    else:
        print("      Skipped: company_analyzer module not available")

    print("\n[6/6] Saving README...")
    save_readme()

    companies_analyzed = (
        company_analysis_result.total_companies if company_analysis_result else "N/A"
    )

    print(f"\n{'=' * 60}")
    print("SUMMARY")
    print(f"{'=' * 60}")
    print(f"  Total jobs: {len(jobs)}")
    print(f"  Açº§ matches (â‰¥80): {sum(1 for j in jobs if j['match_score'] >= 80)}")
    print(f"  Bçº§ matches (â‰¥60): {sum(1 for j in jobs if 60 <= j['match_score'] < 80)}")
    print(f"  Average score: {sum(j['match_score'] for j in jobs) / len(jobs):.1f}")
    print(f"  Companies analyzed: {companies_analyzed}")
    print(f"\n  Quick access: output/latest/")
    print(f"  Full path: {DATE_DIR}")
    print(f"{'=' * 60}\n")


if __name__ == "__main__":
    main()
